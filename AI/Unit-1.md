This analysis provides comprehensive notes on all topics and subtopics found in the sources, formatted exactly as requested.

## Comprehensive AI Notes and Analysis

### 1. Introduction to AI

*   **Topic title with number:** 1. Introduction to AI
*   **Explanation:** Artificial Intelligence (AI) is a rapidly growing field of computer science that aims to create intelligent machines. AI is defined as a branch of computer science that allows us to build machines capable of behaving like a human, thinking like a human, and making decisions. The term itself combines **"man-made" (Artificial)** and **"thinking power" (Intelligence)**. AI enables machines to possess human-based skills such as learning, reasoning, and solving problems. Instead of preprogramming a machine for specific tasks, AI allows the creation of machines with programmed algorithms that operate with their own intelligence.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 1.1 Why Artificial Intelligence?

*   **Topic title with number:** 1.1 Why Artificial Intelligence?
*   **Explanation:** AI allows for the creation of software and devices that solve **real-world problems** efficiently and accurately (e.g., traffic issues, marketing, health concerns). It facilitates the development of **personal virtual assistants** such as Google Assistant, Cortana, or Siri. AI can also build **Robots capable of working in risky environments** where human survival might be threatened, and it opens pathways for new technologies, devices, and opportunities.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 1.2 Goals of Artificial Intelligence

*   **Topic title with number:** 1.2 Goals of Artificial Intelligence
*   **Explanation:** The primary goals include: 1. **Replicating human intelligence**. 2. Solving **knowledge-intensive tasks**. 3. Achieving an intelligent connection between **perception and action**. 4. Building machines that can perform tasks requiring human intelligence (e.g., planning surgical operations, proving a theorem, playing chess, or driving a car in traffic). 5. Creating systems that exhibit intelligent behavior, **learn new things by themselves**, demonstrate, explain, and advise users.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 1.3 What Comprises to Artificial Intelligence?

*   **Topic title with number:** 1.3 What Comprises to Artificial Intelligence?
*   **Explanation:** Intelligence is an intangible combination of Reasoning, learning, problem-solving, perception, and language understanding. To implement these intelligent factors in a machine, AI requires contributions from several disciplines, making it a very vast field.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram showing AI surrounded by contributing fields: Maths, Computer Science, Sociology, Psychology, Biology, Philosophy, Neuron Science, Statistics).
*   **Output or Result (N/A):** N/A

### 1.4 Advantages of Artificial Intelligence

*   **Topic title with number:** 1.4 Advantages of Artificial Intelligence
*   **Explanation:** AI systems offer **High Accuracy with less error** because decisions are based on pre-experience or information. They offer **High-Speed** decision-making, capable of beating chess champions, and provide **High reliability**, performing the same action multiple times accurately. AI is **Useful for risky areas** (e.g., defusing bombs or exploring the ocean floor), provides **Digital Assistants** (used by e-commerce sites), and functions as a **public utility** (e.g., facial recognition or self-driving cars).
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 1.5 Disadvantages of Artificial Intelligence

*   **Topic title with number:** 1.5 Disadvantages of Artificial Intelligence
*   **Explanation:** Drawbacks include **High Cost** for required hardware, software, and maintenance. AI machines **Can't think out of the box**; they only execute the work they were trained or programmed for. They have **No feelings and emotions**, meaning they cannot form emotional attachments and may sometimes pose harm if proper care is not taken. Their presence can **Increase dependency on machines**, potentially causing people to lose their mental capabilities, and AI lacks **Original Creativity** compared to human imagination.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 1.7 Types of Artificial Intelligence

*   **Topic title with number:** 1.7 Types of Artificial Intelligence
*   **Explanation:** AI can be primarily categorized based on **capabilities (Type-1)** and **functionality (Type-2)**.

#### Type-1: Based on Capabilities

*   **Narrow AI (Weak AI):** Performs a **dedicated task** with intelligence. It is the most common AI available today (e.g., Apple Siri, playing chess, self-driving cars). It cannot work beyond its specific limitations.
*   **General AI:** Aims to create a system that can perform **any intellectual task efficiently like a human**. Currently, no such system exists.
*   **Super AI (Strong AI):** A hypothetical level where machines **surpass human intelligence** and can perform any task better than humans, possessing cognitive properties like reasoning and planning.

#### Type-2: Based on Functionality

*   **Reactive Machines:** The most basic AI type. They focus only on the current scenario and **do not store memories** or past experiences for future actions. Example: IBM's Deep Blue.
*   **Limited Memory:** Can store past experiences or data for a **short period of time** to use for immediate actions. Example: Self-driving cars storing recent speeds of nearby cars to navigate.
*   **Theory of Mind:** Hypothetical AI that would understand **human emotions and beliefs** and be able to interact socially.
*   **Self-Awareness:** The hypothetical future of AI. These machines would be super intelligent with their **own consciousness, sentiments, and self-awareness**.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Flow diagram showing the two main types: Type-1 (Narrow, General, Strong AI) and Type-2 (Reactive Machines, Limited Memory, Theory of Mind, Self Awareness)).
    *   (Table/List summarizing capabilities: Narrow AI (Dedicated for one task - We are here), General AI (Perform like human), Super AI (Intelligent than human)).
*   **Output or Result (N/A):** N/A

### 1.8 Application of AI

*   **Topic title with number:** 1.8 Application of AI
*   **Explanation:** AI is crucial today because it can solve complex problems across industries like Healthcare, finance, entertainment, and education. Applications include:
    *   **Healthcare:** Making faster and better diagnoses, and alerting doctors when patients are worsening.
    *   **Gaming:** Used for strategic games like chess where machines must think of many possible places.
    *   **Finance:** Implementing automation, algorithm trading, and chatbots.
    *   **Data Security:** Making data safer and detecting cyber-attacks (e.g., AEG bot).
    *   **Social Media:** Organizing and managing billions of user profiles and identifying trends.
    *   **Automotive Industry:** Used in self-driven cars and virtual assistants like TeslaBot.
    *   **Robotics:** Creating intelligent robots (like Erica and Sophia) that perform tasks based on experience rather than just pre-programmed actions.
    *   **Entertainment:** Providing recommendations on services like Netflix or Amazon using ML/AI algorithms.
    *   **E-commerce:** Helping shoppers discover associated products with recommendations.
    *   **Education:** Automating grading and functioning as virtual tutors or teaching assistants.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram listing application sectors: Astronomy, Data Security, Social Media, Automotive, Robotics, Finance, Entertainment, Gaming, E-commerce, Healthcare, Transport, Agriculture, Education).
*   **Output or Result (N/A):** N/A

### 2.1 Agents in Artificial Intelligence

*   **Topic title with number:** 2.1 Agents in Artificial Intelligence
*   **Explanation:** An agent is fundamentally anything that **perceives its environment through sensors** and **acts upon that environment through actuators**. The agent operates in a continuous cycle of perceiving, thinking, and acting.
    *   **Sensors:** Devices that detect environmental changes (e.g., human eyes, camera).
    *   **Actuators:** Components that convert energy into motion to control a system (e.g., electric motor).
    *   **Effectors:** Devices that directly influence the environment (e.g., display screen, legs).
    *   **Environment:** Everything surrounding the agent that provides input to sense and act upon.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram showing: Environment <-> (Sensors/Percepts) Agent (Actuators/Effectors) <-> Environment).
*   **Output or Result (N/A):** N/A

### 2.2 Intelligent Agents

*   **Topic title with number:** 2.2 Intelligent Agents
*   **Explanation:** An intelligent agent is an **autonomous entity** that uses its sensors and actuators to achieve defined goals, often by learning from the environment.
*   **Four Rules for AI Agents:** Agents must have the ability to perceive the environment, use that observation to make decisions, let the decision result in an action, and ensure that the action taken is a **rational action**.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 2.3 Types of AI Agents

*   **Topic title with number:** 2.3 Types of AI Agents
*   **Explanation:** Agents are categorized into five types based on their capability and perceived intelligence: Simple Reflex, Model-based Reflex, Goal-based, Utility-based, and Learning agents.

#### 1. Simple Reflex agent

*   **Explanation:** These agents are the simplest, relying **only on current percepts** and ignoring all past percept history to make decisions. They operate based on a **Condition-action rule** and only succeed in a **fully observable environment**.
*   **Algorithm (Child's Version):** **The Traffic Light Follower:** If you see Red light (Condition/Percept), you Stop (Action). You don't remember if the previous light was green or if you were speeding; you only care about the signal right now. *Keywords: Current percepts, Condition-action rule, Fully observable.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram showing direct path: Percepts -> What the world is like now -> Condition-action rules -> Action).
*   **Output or Result:** Very limited intelligence; not adaptive to environmental changes.

#### 2. Model-based reflex agent

*   **Explanation:** These agents can work in a **partially observable environment** by keeping track of the situation. They use a **Model** (knowledge of "how things happen in the world") and maintain an **Internal State** (a representation of the current state based on percept history).
*   **Algorithm (Child's Version):** **The Navigating Robot:** The robot is walking on a floor covered partially by a curtain (partially observable). It remembers that it just took three steps forward (Internal State) and knows that three steps usually equals six feet (Model: how the world evolves). It uses this memory to guess its true location, even though it can't see the whole floor right now. *Keywords: Partially observable environment, Model, Internal State, Percept history.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram showing Percepts updating State, and the State influencing Condition-action rules alongside the Model (How the world evolves/What my actions do)).
*   **Output or Result:** Able to track situations in environments where information is incomplete.

#### 3. Goal-based agents

*   **Explanation:** They expand on Model-based agents by having a specific **"goal"** (a desirable situation). They choose actions that help achieve this goal. This involves **searching and planning** long sequences of possible actions to reach the destination, making them proactive.
*   **Algorithm (Child's Version):** **The Trip Planner:** You want to travel from London to Edinburgh (Goal). The agent maps the current state (London) to the goal state (Edinburgh) and calculates different routes (searching and planning). It is proactive because it considers future outcomes before taking the first step. *Keywords: Goal, Searching, Planning, Proactive.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram similar to Model-based but adding a "Goals" box influencing the decision process).
*   **Output or Result:** Behavior optimized for achieving a specific target situation.

#### 4. Utility-based agents

*   **Explanation:** Similar to goal-based agents but include a **utility measurement** component. They seek to achieve the goal in the **best possible way** (maximizing efficiency or desirability). The utility function maps states to a real number to assess success. They are essential when the agent must choose the optimal action among multiple possible alternatives.
*   **Algorithm (Child's Version):** **The Optimal Router:** You have two paths to your Goal: Path A is fast but expensive (low utility score), Path B is slow but free (high utility score). The agent calculates the **Utility** (how happy it will be/how well it performs) for both and chooses the path that yields the highest score according to its preferences (e.g., maximizing speed). *Keywords: Utility measurement, Best way, Optimal action, Utility function.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram similar to Goal-based but includes a "Utility" box that assesses "How happy I will be In such a state").
*   **Output or Result:** Optimal choices that maximize performance among competing alternatives.

#### 5. Learning Agents

*   **Explanation:** Agents that can **learn from past experiences** and automatically adapt their behavior. They start with basic knowledge and improve over time.
*   **Conceptual Components:**
    *   **Learning element:** Improves the agent based on experience.
    *   **Critic:** Provides feedback on the agent's performance relative to a standard.
    *   **Performance element:** Selects the external action.
    *   **Problem generator:** Suggests actions that lead to new, informative experiences.
*   **Algorithm (Child's Version):** **The Self-improving Shooter Game:** The **Performance element** fires a shot (action). The **Critic** sees the shot missed (negative feedback). The **Learning element** adjusts the aim sensitivity for the next shot. The **Problem generator** might suggest trying a new gun to gain new knowledge about aiming. *Keywords: Learn from past experiences, Learning element, Critic, Performance element, Problem generator.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram showing the relationship between the four conceptual components: Critic, Learning element, Performance element, and Problem Generator, all interacting with the Environment based on a Performance Standard).
*   **Output or Result:** Continuous self-improvement and adaptation.

### 3. Rational Agent

*   **Topic title with number:** 3. Rational Agent
*   **Explanation:** A rational agent is defined as an agent that takes actions intended to **maximize its performance measure**, based on clear preferences and models of uncertainty. The core idea of AI is building rational agents.
*   **3.1 Rationality:** Rationality is judged based on four points: the **Performance measure** (success criteria), the agent's **prior knowledge** of its environment, the **best possible actions** it can perform, and the **sequence of percepts** it receives.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 4. Nature of Environment

*   **Topic title with number:** 4. Nature of Environment
*   **Explanation:** Environments have various features that affect how an agent operates:
    *   **Fully observable vs Partially Observable:** Fully observable means sensors access the complete state; partially observable means they do not.
    *   **Deterministic vs Stochastic:** Deterministic means the next state is completely determined by the current state and action; stochastic environments are random and cannot be fully determined.
    *   **Episodic vs Sequential:** Episodic involves a series of one-shot actions (only current percept needed); Sequential requires memory of past actions to determine the next best action.
    *   **Single-agent vs Multi-agent:** Single-agent involves one agent operating alone; multi-agent involves multiple agents.
    *   **Static vs Dynamic:** Static environments do not change while the agent is deliberating (e.g., Crossword puzzles); Dynamic environments change while the agent deliberates (e.g., Taxi driving).
    *   **Discrete vs Continuous:** Discrete environments have a finite number of percepts and actions (e.g., Chess game); Continuous environments do not (e.g., Self-driving car).
    *   **Known vs Unknown:** Known environment results for all actions are known; Unknown environment requires the agent to learn how it works.
    *   **Accessible vs Inaccessible:** Accessible means the agent can obtain complete and accurate information about the state; Inaccessible means it cannot.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 5. Structure of an AI Agent

*   **Topic title with number:** 5. Structure of an AI Agent
*   **Explanation:** The structure of an intelligent agent is the sum of its architecture and its program: **Agent = Architecture + Agent program**.
    *   **Architecture:** The physical hardware/machinery the agent executes on.
    *   **Agent Function ($f:P^{*}\rightarrow A$):** Maps a percept sequence to an action.
    *   **Agent Program:** The implementation of the agent function that runs on the architecture.
*   **PEAS Representation:** A model used to define the properties of a rational agent.
    *   **P:** Performance measure (The objective for success).
    *   **E:** Environment.
    *   **A:** Actuators.
    *   **S:** Sensors.
*   **Example (Self-driving car):**
    *   **Performance:** Safety, time, comfort, legal drive.
    *   **Environment:** Roads, pedestrians, road signs, other vehicles.
    *   **Actuators:** Steering, accelerator, brake, horn.
    *   **Sensors:** Camera, GPS, speedometer, accelerometer, sonar.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 6. Problem-solving agents

*   **Topic title with number:** 6. Problem-solving agents
*   **Explanation:** These are **goal-based agents** that utilize atomic representation and employ search strategies/algorithms to solve problems and find the best outcome.
*   **Five Steps to Solve a Problem Using AI:**
    1.  Analyzing the problem.
    2.  Defining the problem.
    3.  Identification of solutions.
    4.  Choosing the solution.
    5.  Implementation.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Flow diagram showing the steps: ANALYZING THE PROBLEM -> DEFINING THE PROBLEM -> IDENTIFICATION OF SOLUTIONS -> CHOOSING THE SOLUTION -> IMPLEMENTATION).
*   **Output or Result (N/A):** N/A

### 7. Problem Searching

*   **Topic title with number:** 7. Problem Searching
*   **Explanation:** Searching is a key problem-solving technique in AI, defined as the step-by-step procedure used to find a solution within a given search space.
*   **Search Terminologies:**
    *   **Search Space:** The set of all possible solutions.
    *   **Start State:** The point where the search begins.
    *   **Goal Test:** Checks if the required goal state has been reached.
    *   **Solution:** An action sequence that links the start node to the goal node.
    *   **Optimal Solution:** The solution with the lowest cost.
*   **7.2 Properties of Search Algorithms:** Used to measure efficiency:
    *   **Completeness:** Guaranteed to find a solution if one exists.
    *   **Optimality:** Guaranteed to find the best solution (lowest path cost).
    *   **Time Complexity:** Time required to complete the task.
    *   **Space Complexity:** Maximum memory storage required during the search.
*   **Algorithm (N/A):** N/A
*   **Codes (N/A):** N/A
*   **Diagrams (N/A):** N/A
*   **Output or Result (N/A):** N/A

### 8. Uninformed Search Algorithms

*   **Topic title with number:** 8. Uninformed Search Algorithms
*   **Explanation:** Also known as **blind search**, these brute-force algorithms operate without any domain knowledge (like goal location or closeness). They only contain information about how to traverse the search tree.

#### 1. Breadth-first Search (BFS)

*   **Explanation:** Traverses the graph or tree **level by level (breadth wise)**. It expands all nodes at the current depth before moving to the next depth. BFS is implemented using a **FIFO queue**.
*   **Algorithm (Child's Version):** **The Floor Sweeper:** Imagine a building. To find a secret room, you must check every corner of the first floor. Once the entire first floor is clear, you move to the second floor and check every corner there. You check all options at one level before going deeper. This method guarantees you find the *closest* room first. *Keywords: Breadth wise, FIFO queue, Minimal solution, Level by level.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Tree diagram showing layer-by-layer traversal from S to K).
*   **Output or Result:** **Complete** (will find a solution if one exists). **Optimal** (if path cost is a non-decreasing function of depth). Requires lots of memory. Time Complexity: $O(b^d)$. Space Complexity: $O(b^d)$.

#### 2. Depth-first Search (DFS)

*   **Explanation:** A recursive algorithm that explores each path as far as possible, going to its **greatest depth** before backtracking. DFS uses a **stack** data structure.
*   **Algorithm (Child's Version):** **The Cave Explorer:** You enter a cave and take the very first tunnel you see. You keep walking deeper and deeper until you hit a wall (dead end). You then walk backward only until you find the last intersection and try the next available tunnel from there. This takes less time if the goal is deep, and saves space because you only remember the path you are currently on. *Keywords: Greatest depth, Recursive, Stack, Backtracking.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Tree diagram showing flow S -> A -> B -> D -> E, followed by backtracking).
*   **Output or Result:** Requires **very less memory**. **Complete** within finite state space. **Non-optimal** (may find a high-cost solution). Risk of going into an infinite loop. Time Complexity: $O(n^m)$. Space Complexity: $O(b^m)$.

#### 3. Depth-Limited Search Algorithm (DLS)

*   **Explanation:** Identical to DFS but includes a **predetermined depth limit (l)**. This fixes the infinite path drawback of DFS. Any node at this limit is treated as if it has no successor nodes.
*   **Algorithm (Child's Version):** **The Restricted Explorer:** This is the Cave Explorer, but before they enter, a rule is set: "You cannot go past 10 meters deep" (Depth Limit). If the goal is at 5 meters, you find it. If the goal is at 15 meters, the search fails with a "Cutoff failure" because the limit was reached. *Keywords: Predetermined limit, Cutoff failure, Memory efficient.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Tree diagram illustrating nodes searched within a limited depth).
*   **Output or Result:** Memory efficient. **Incomplete** if the solution is beyond the limit. **Not optimal**. Time Complexity: $O(b^l)$. Space Complexity: $O(b \times l)$.

#### 4. Uniform-cost Search Algorithm (UCS)

*   **Explanation:** Used for searching in a **weighted graph/tree** where each edge has a different cost. Its goal is to find the path with the **lowest cumulative cost** from the root. UCS uses a **priority queue** and is equivalent to BFS if all path costs are the same.
*   **Algorithm (Child's Version):** **The Budget Traveler:** You have to find a destination, and every road segment costs money. UCS always prioritizes expanding the path that has the cheapest total cost so far. If a path is very long but dirt cheap, you check it before checking a short, expensive path. This guarantees you find the most cost-effective route. *Keywords: Weighted tree, Lowest cumulative cost, Priority queue, Optimal.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Tree diagram showing nodes and edges labeled with path costs).
*   **Output or Result:** **Optimal** (always selects the lowest path cost). **Complete**. Can get stuck in an infinite loop if costs are not positive/increasing. Time Complexity: $O(b^{1+[C^{*}/\epsilon]})$. Space Complexity: $O(b^{1+[C^{*}/\epsilon]})$.

#### 5. Iterative deepening depth-first Search (IDDFS)

*   **Explanation:** Combines the speed benefits of BFS with the memory efficiency of DFS. It finds the best depth limit by **gradually increasing the limit** (l = 1, then l = 2, then l = 3, etc.) and running DFS repeatedly until the goal is found. It is useful when the goal depth is unknown.
*   **Algorithm (Child's Version):** **The Incremental Surveyor:** First, you run DLS with limit 1. If you don't find the goal, you throw away that work, increase the limit to 2, and start DLS all over again. You keep repeating the entire search until the goal is found. Though it repeats work (a drawback), it guarantees finding the shallowest solution (like BFS) while using minimal memory (like DFS). *Keywords: Combination of DFS and BFS, Gradually increasing depth limit, Memory efficient.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Tree diagram showing the iterations of search path progression, e.g., 1'st Iteration: S->A).
*   **Output or Result:** **Optimal** (if path cost is non-decreasing with depth). **Complete** (if branching factor is finite). Time Complexity: $O(b^d)$. Space Complexity: $O(bd)$.

#### 6. Bidirectional Search Algorithm

*   **Explanation:** Runs two searches simultaneously: a **forward-search** from the initial state and a **backward-search** from the goal state. The algorithm terminates when these two search frontiers **intersect**. It can use search techniques like BFS or DFS.
*   **Algorithm (Child's Version):** **The Two-Way Tunnel Digger:** Instead of digging a long tunnel from the start to the end, you start digging from the Goal at the same time you start digging from the Start. Because the search space is cut in half, the two tunnels meet much faster. *Keywords: Two simultaneous searches, Forward-search, Backward-search, Intersect.*
*   **Codes (N/A):** N/A
*   **Diagrams if exists:**
    *   (Diagram showing two simultaneous searches starting at Node 1 and Goal Node 16, meeting at an Intersection Node 9).
*   **Output or Result:** **Fast** and requires **less memory**. **Optimal**. **Complete** if BFS is used for both searches. Disadvantage: Requires knowing the goal state in advance.